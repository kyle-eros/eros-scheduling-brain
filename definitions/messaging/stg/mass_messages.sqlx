config {
  type: "incremental",
  schema: "eros_messaging_stg",
  uniqueKey: ["message_sk"],
  partitionBy: "sending_date",
  clusterBy: ["username_std"],
  requirePartitionFilter: false,  // Start false for initial creation, can be altered later
  description: "Incremental mass messages with 14-day watermark and robust partition handling",
  labels: {app: "eros", domain: "messaging", layer: "stg"},
  tags: ["messaging_stg"],
  assertions: {
    uniqueKey: ["message_sk"],
    nonNull: ["message_sk", "sending_date", "username_std"],
    rowConditions: [
      "sending_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 14 DAY)"
    ]
  }
}

post_operations {
  ALTER TABLE ${self()} SET OPTIONS (require_partition_filter = TRUE);
}

/*
 * MASS MESSAGES - INCREMENTAL STAGING TABLE
 *
 * Purpose: Consolidates historical and daily mass message data with incremental updates
 *
 * Partitioning Strategy:
 * - Partitioned by sending_date for cost-efficient queries
 * - Requires partition filter to prevent expensive full table scans
 * - Uses 14-day watermark to capture late-arriving data
 *
 * Incremental Logic:
 * - Primary watermark: sending_ts (timestamp precision)
 * - Lookback window: 14 days to catch delayed records
 * - Deduplication: QUALIFY with ROW_NUMBER to ensure unique message_sk
 *
 * Data Quality:
 * - Enforces non-null constraints on key fields
 * - Validates unique message_sk
 * - Monitors for data freshness
 */

WITH
historical_source AS (
  SELECT
    CAST(message_id AS STRING) as message_id,
    CAST(sender AS STRING) as sender,
    CAST(sending_time AS STRING) as sending_time,
    CAST(price AS STRING) as price,
    SAFE_CAST(sent AS INT64) as sent,
    SAFE_CAST(viewed AS INT64) as viewed,
    SAFE_CAST(purchased AS INT64) as purchased,
    CAST(earnings AS STRING) as earnings,
    message as message_text,
    'historical' as source_file
  FROM ${ref("facts_messages_all")}
  WHERE sending_time IS NOT NULL AND TRIM(sending_time) != ''
),

daily_source AS (
  SELECT
    CAST(message_id AS STRING) as message_id,
    CAST(sender AS STRING) as sender,
    CAST(sending_time AS STRING) as sending_time,
    CAST(price AS STRING) as price,
    SAFE_CAST(sent AS INT64) as sent,
    SAFE_CAST(viewed AS INT64) as viewed,
    SAFE_CAST(purchased AS INT64) as purchased,
    CAST(earnings AS STRING) as earnings,
    message as message_text,
    'daily' as source_file
  FROM ${ref("mass_message_daily_final")}
  WHERE sending_time IS NOT NULL AND TRIM(sending_time) != ''
),

messages_unioned AS (
  SELECT * FROM historical_source
  UNION ALL
  SELECT * FROM daily_source
),

messages_cleaned AS (
  SELECT
    ${df_mk_sk(["'MASS_MESSAGES'", "CAST(message_id AS STRING)", "source_file"])} as message_sk,
    ${df_std_username('sender')} as username_std,
    COALESCE(
      SAFE.PARSE_TIMESTAMP('%Y-%m-%dT%H:%M:%E*S%Ez', sending_time),
      SAFE.PARSE_TIMESTAMP('%Y-%m-%d %H:%M:%S', sending_time)
    ) as sending_ts,
    ${df_safe_cast_numeric('price', 'FLOAT64')} as price,
    sent as sent_count,
    viewed as viewed_count,
    purchased as purchased_count, 
    ${df_safe_cast_numeric('earnings', 'FLOAT64')} as earnings_total,
    message_text,
    source_file,
    CURRENT_TIMESTAMP() as loaded_at
  FROM messages_unioned
),

messages_final AS (
  SELECT
    *,
    DATE(sending_ts) as sending_date
  FROM messages_cleaned
  WHERE sending_ts IS NOT NULL
)

SELECT * FROM messages_final
WHERE
  -- ALWAYS include partition filter for performance and cost control
  sending_date >= DATE('2024-01-01')  -- Historical cutoff
  AND sending_date <= CURRENT_DATE()  -- No future dates

${ when(incremental(), `
  -- Additional incremental filters for recent data
  AND sending_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 14 DAY)
  AND (
    -- New records based on timestamp watermark
    sending_ts > COALESCE(
      (SELECT MAX(sending_ts)
       FROM ${self()}
       WHERE sending_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY)),
      TIMESTAMP('2024-01-01')
    )
    -- Or recently loaded records (catch late arrivals)
    OR loaded_at >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 24 HOUR)
  )
`) }

QUALIFY ROW_NUMBER() OVER (
  PARTITION BY message_sk
  ORDER BY loaded_at DESC
) = 1