config {
  type: "incremental",
  schema: "eros_messaging_stg", 
  uniqueKey: ["message_sk"],
  partitionBy: "sending_date",
  clusterBy: ["username_std"],
  requirePartitionFilter: true,
  description: "Incremental mass messages with 14-day watermark",
  labels: {app: "eros", domain: "messaging", layer: "stg"},
  tags: ["messaging_stg"]
}

WITH 
historical_source AS (
  SELECT
    CAST(message_id AS STRING) as message_id,
    CAST(sender AS STRING) as sender,
    CAST(sending_time AS STRING) as sending_time,
    CAST(price AS STRING) as price,
    SAFE_CAST(sent AS INT64) as sent,
    SAFE_CAST(viewed AS INT64) as viewed,
    SAFE_CAST(purchased AS INT64) as purchased,
    CAST(earnings AS STRING) as earnings,
    message as message_text,
    'historical' as source_file
  FROM ${ref("facts_messages_all")}
  WHERE sending_time IS NOT NULL AND TRIM(sending_time) != ''
),

daily_source AS (
  SELECT
    CAST(message_id AS STRING) as message_id,
    CAST(sender AS STRING) as sender,
    CAST(sending_time AS STRING) as sending_time,
    CAST(price AS STRING) as price,
    SAFE_CAST(sent AS INT64) as sent,
    SAFE_CAST(viewed AS INT64) as viewed,
    SAFE_CAST(purchased AS INT64) as purchased,
    CAST(earnings AS STRING) as earnings,
    message as message_text,
    'daily' as source_file
  FROM ${ref("mass_message_daily_final")}
  WHERE sending_time IS NOT NULL AND TRIM(sending_time) != ''
),

messages_unioned AS (
  SELECT * FROM historical_source
  UNION ALL
  SELECT * FROM daily_source
),

messages_cleaned AS (
  SELECT
    ${df_mk_sk(["'MASS_MESSAGES'", "CAST(message_id AS STRING)", "source_file"])} as message_sk,
    ${df_std_username('sender')} as username_std,
    COALESCE(
      SAFE.PARSE_TIMESTAMP('%Y-%m-%dT%H:%M:%E*S%Ez', sending_time),
      SAFE.PARSE_TIMESTAMP('%Y-%m-%d %H:%M:%S', sending_time)
    ) as sending_ts,
    ${df_safe_cast_numeric('price', 'FLOAT64')} as price,
    sent as sent_count,
    viewed as viewed_count,
    purchased as purchased_count, 
    ${df_safe_cast_numeric('earnings', 'FLOAT64')} as earnings_total,
    message_text,
    source_file,
    CURRENT_TIMESTAMP() as loaded_at
  FROM messages_unioned
),

messages_final AS (
  SELECT
    *,
    DATE(sending_ts) as sending_date
  FROM messages_cleaned
  WHERE sending_ts IS NOT NULL
)

SELECT * FROM messages_final
WHERE sending_date >= DATE '2024-01-01'
  
${ when(incremental(), `
  AND sending_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 14 DAY)
  AND sending_ts > (SELECT MAX(sending_ts) FROM ${self()} WHERE sending_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY))
`) }

QUALIFY ROW_NUMBER() OVER (
  PARTITION BY message_sk 
  ORDER BY loaded_at DESC
) = 1